{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_all_22.txt','rb') as file:\n",
    "    dataframe_train=pickle.load(file)\n",
    "train, test = train_test_split(dataframe_train, test_size=0.2, random_state=1)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_= 22 # control the number of features\n",
    "#dataframe_train.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport sys\\n\\nLI=[]\\nfor name in dataframe_train.columns[1:]:\\n        fig, ax = plt.subplots(figsize=(5, 4))\\n        for group in [0,1]:\\n            try:\\n                sns.distplot(dataframe_train.loc[dataframe_train.Label == group, name],kde=True, label=group)\\n            except:\\n                LI.append(name)  \\n        ax.set_ylabel('Total Count')\\n        ax.set_title(name)\\n        ax.legend()\\n\""
      ]
     },
     "execution_count": 1144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'''\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "LI=[]\n",
    "for name in dataframe_train.columns[1:]:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        for group in [0,1]:\n",
    "            try:\n",
    "                sns.distplot(dataframe_train.loc[dataframe_train.Label == group, name],kde=True, label=group)\n",
    "            except:\n",
    "                LI.append(name)  \n",
    "        ax.set_ylabel('Total Count')\n",
    "        ax.set_title(name)\n",
    "        ax.legend()\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "X_train = train.drop('Label',axis=1)\n",
    "y_train = train.Label\n",
    "\n",
    "# est set\n",
    "X_test = test.drop('Label',axis=1)\n",
    "y_test = test.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "statictial selection\n",
    "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2,f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# the score for all features\\nfor i in range(len(fs.scores_)):\\n    print('Feature %d: %f' % (i, fs.scores_[i]))\\n\""
      ]
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = SelectKBest(score_func=f_classif, k=k_)\n",
    "fs.fit(X_train,y_train)\n",
    "'''\n",
    "# the score for all features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = fs.transform(X_train)\n",
    "\n",
    "x_test = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnb = gnb_model.predict(x_test)\n",
    "probnb = gnb_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of Naive Bayes: 0.998\n"
     ]
    }
   ],
   "source": [
    "nb=roc_auc_score(y_test,labelnb)\n",
    "ac1=precision_score(y_test,labelnb)\n",
    "print('The ROC of Naive Bayes: %5.3f' %(nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 1155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model = LogisticRegression(penalty ='none',max_iter=500)\n",
    "LR_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predict=LR_model.predict(x_test)\n",
    "prob_preidct=LR_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of Logistic Regression: 0.528\n"
     ]
    }
   ],
   "source": [
    "rl=roc_auc_score(y_test,label_predict)\n",
    "ac2=precision_score(y_test,label_predict)\n",
    "print('The ROC of Logistic Regression: %5.3f' %(rl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model=DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "rf_model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "labeldt=dt_model.predict(x_test)\n",
    "probdt = dt_model.predict_proba(x_test)\n",
    "\n",
    "# Random Forest\n",
    "labelrf = rf_model.predict(x_test)\n",
    "probrf = rf_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of Decision Tree: 1.000\n",
      "The ROC of Random Forest: 1.000\n"
     ]
    }
   ],
   "source": [
    "dt=roc_auc_score(y_test,labeldt)\n",
    "ac3=precision_score(y_test,labeldt)\n",
    "print('The ROC of Decision Tree: %5.3f' %(dt))\n",
    "rf=roc_auc_score(y_test,labelrf)\n",
    "ac4=precision_score(y_test,labelrf)\n",
    "print('The ROC of Random Forest: %5.3f' %(rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelknn = knn.predict(x_test)\n",
    "probrknn = knn.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of KNN: 1.000\n"
     ]
    }
   ],
   "source": [
    "kn=roc_auc_score(y_test,labelknn)\n",
    "ac5=precision_score(y_test,labelknn)\n",
    "print('The ROC of KNN: %5.3f' %(kn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SGDClassifier with Loss='log' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=False,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDcl=SGDClassifier(loss='log',max_iter=1000, tol=1e-3,fit_intercept=False)  \n",
    "SGDcl.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predictC=SGDcl.predict(x_test)\n",
    "prob_preidctC=SGDcl.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of SGDClassifier: 1.000\n"
     ]
    }
   ],
   "source": [
    "cl=roc_auc_score(y_test,label_predictC)\n",
    "ac6=precision_score(y_test,label_predictC)\n",
    "print('The ROC of SGDClassifier: %5.3f' %(cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVM \n",
    "with RFE feature selection: recusive feature selection (model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "estimator = SVR(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE_model = RFE(estimator, n_features_to_select=20, step=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "selector = RFE_model.fit(X_train, y_train)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=True,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train=selector.transform(X_train)\n",
    "SVM_model = make_pipeline(StandardScaler(), SVC(gamma='auto',probability=True))\n",
    "SVM_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsvm = SVM_model.predict(x_test)\n",
    "probrsvm = SVM_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of SVM: 1.000\n"
     ]
    }
   ],
   "source": [
    "svm=roc_auc_score(y_test,labelsvm)\n",
    "ac7=precision_score(y_test,labelsvm)\n",
    "print('The ROC of SVM: %5.3f' %(svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(10),activation='logistic', random_state=1,max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=10, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=3000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "probmlp=mlp_model.predict_proba(x_test)\n",
    "labelmlp=mlp_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC of MLP: 1.000\n"
     ]
    }
   ],
   "source": [
    "mlp=roc_auc_score(y_test,labelmlp)\n",
    "ac8=precision_score(y_test,labelmlp)\n",
    "print('The ROC of MLP: %5.3f' %(mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RFE Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "estimator = SVR(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RFE_model = RFE(estimator, n_features_to_select=k_, step=1)\n",
    "RFE_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labelrfe = RFE_model.predict(x_test)\n",
    "l=list(labelrfe)\n",
    "ll=[]\n",
    "for elem in l:\n",
    "    if elem <=0.5:\n",
    "        ll.append(0)\n",
    "    else:\n",
    "        ll.append(1)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rfe=roc_auc_score(list(y_test),ll)\n",
    "ac9=precision_score(list(y_test),ll)\n",
    "print('The ROC score: %5.3f' %(rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [nb,rl,dt,rf,kn,cl,svm,mlp]#,rfe\n",
    "precision=[ac1,ac2,ac3,ac4,ac5,ac6,ac7,ac8]#ac9\n",
    "index1= ['Naive Bayes','Logistic Regression','Decision Tree','Random Forest','K-Nearest Neighbor','SGDClassifier','SVM','Multilayer Perceptron']#'Recursive Feature Elimination'\n",
    "result = pd.DataFrame(score,index=index1, columns=['ROC'])\n",
    "result['Precision'] = precision\n",
    "#result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the Given DataSet with Probability\n",
    "\n",
    "Untill now **Random Forest** gives the higtest ROC score 0.7622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_22.txt','rb') as file:\n",
    "    test=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = fs.transform(test)\n",
    "Test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Choose the features that is in the Trainset\n",
    "Test=Test.iloc[:,4:]\n",
    "Test=Test.drop('CN',axis=1)\n",
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ID.txt','rb') as file:\n",
    "    ID=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(probs, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write('Id,Predicted\\n')\n",
    "        for i, p in zip(ID, probs):\n",
    "            file.write(\"{},{}\\n\".format(i, p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission1(probs, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write('Id,Predicted\\n')\n",
    "        for i, p in zip(ID, probs):\n",
    "            file.write(\"{},{}\\n\".format(i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the models without transformed X\n",
    "clf1 = [LR_model,dt_model,rf_model,knn,gnb_model]\n",
    "prob1=[]\n",
    "for clf in clf1:\n",
    "    prob=clf.predict_proba(Test)\n",
    "    prob1.append(prob)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob=LR_model.predict_proba(Test)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(prob1[0], 'LR_submit.csv')\n",
    "submission(prob1[1], 'DT_submit.csv')\n",
    "submission(prob1[2], 'RF_submit.csv')\n",
    "submission(prob1[3], 'KNN_submit.csv')\n",
    "submission(prob1[4], 'NB_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the models with transformed X\n",
    "clf2=[SGDcl,SVM_model,mlp_model]\n",
    "Test_=scaler.transform(Test)\n",
    "prob2=[]\n",
    "for clf in clf2:\n",
    "    prob=clf.predict_proba(Test_)\n",
    "    prob2.append(list(prob))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prob=mlp_model.predict_proba(Test_)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(prob2[0], 'SGD_submit.csv')\n",
    "submission(prob2[1], 'SVM_submit.csv')\n",
    "submission(prob2[2], 'MLP_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission1(probrfe, 'RFE_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs=['NB_submit.csv','LR_submit.csv','DT_submit.csv','RF_submit.csv','KNN_submit.csv','SGD_submit.csv','SVM_submit.csv','MLP_submit.csv']#'RFE_submit.csv\n",
    "P=[]\n",
    "N=[]\n",
    "for csv in csvs:\n",
    "    dd=pd.read_csv(csv)\n",
    "    l=list(dd.Predicted)\n",
    "    z=[]\n",
    "    o=[]\n",
    "    for elem in l:\n",
    "        if elem <=0.5:\n",
    "            z.append(elem)\n",
    "        else:\n",
    "            o.append(elem)\n",
    "    P.append(len(o))\n",
    "    N.append(len(z))\n",
    "result['Positive'] = P\n",
    "result['Negative'] = N\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
