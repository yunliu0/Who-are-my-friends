{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph.txt', 'rb') as file:\n",
    "    graph = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_neg_30000.txt', 'rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('16_test.txt', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test w/o label\n",
    "source=test.Source\n",
    "sink=test.Sink\n",
    "dataframe_train=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train w label\n",
    "dataframe_train=pd.DataFrame()\n",
    "source=train.Source\n",
    "sink=train.Sink\n",
    "Label=train.Label\n",
    "dataframe_train['Label']=Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source following\n",
    "following_so=[]\n",
    "for elem in source:\n",
    "    following_so.append(graph.out_degree(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['Source_following']=following_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sink following\n",
    "following_si=[]\n",
    "for elem in sink:\n",
    "    following_si.append(graph.out_degree(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['Sink_following']=following_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source follower\n",
    "follower_so=[]\n",
    "for elem in source:\n",
    "    follower_so.append(graph.in_degree(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['Source_follower']=follower_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sink follower\n",
    "follower_si=[]\n",
    "for elem in sink:\n",
    "    follower_si.append(graph.in_degree(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['Sink_follower']=follower_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest_path\n",
    "shortest_path=[]\n",
    "for i in range(len(source)):\n",
    "    try:\n",
    "        ll=nx.shortest_path_length(graph,source[i],sink[i])\n",
    "    except:\n",
    "        ll=0\n",
    "    shortest_path.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the number of unique path length\n",
    "x = np.array(shortest_path)\n",
    "np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['Shortest_path']=shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Number of zeros:')\n",
    "dataframe_train.isin([0]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Functions for Directed Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out Degree\n",
    "def getNeighbors_Source(node, graph):\n",
    "    nei = [n for n in graph.neighbors(node)]\n",
    "    return nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Degree\n",
    "def getNeighbors_Sink(node, graph):\n",
    "    nei = [n for n in graph.predecessors(node)]\n",
    "    return nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Neighbors\n",
    "def CN(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    cn = len(set(nei1).intersection(set(nei2)))\n",
    "    return cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the Neighbors for the Two Nodes\n",
    "def union(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    union = len(set(nei1).union(set(nei2)))\n",
    "    return union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Coefficient\n",
    "def JC(n1,n2,graph):\n",
    "    cn = CN(n1,n2,graph)\n",
    "    un = union(n1,n2,graph)\n",
    "    jc = cn/(un+1)\n",
    "    return jc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamic Adar Index\n",
    "def AAI(n1, n2, graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)  \n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    \n",
    "    aai = 0\n",
    "    for i in cn:\n",
    "        n = getNeighbors_Source(i, graph)\n",
    "        num = len(n)\n",
    "        aai += 1 / math.log(num + 0.5)   \n",
    "    return aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferential Attachment (*)\n",
    "def PA(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    pa = len(nei1)*len(nei2)\n",
    "    return pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN/+\n",
    "def SI(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    add = cn/(len(nei1) + len(nei2))\n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN/min()\n",
    "def HP(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    try:\n",
    "        hp = len(cn)/min(len(nei1),len(nei2))\n",
    "    except:\n",
    "        hp=0\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN/max()\n",
    "def HD(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)\n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    hd = cn/max(len(nei1),len(nei2))\n",
    "    return hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Allocation Index\n",
    "def RA(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)  \n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    \n",
    "    ra = 0\n",
    "    for i in cn:\n",
    "        n = getNeighbors_Source(i, graph)\n",
    "        num = len(n)\n",
    "        ra += 1 / (num + 0.5)\n",
    "    return ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN/PA\n",
    "def LHN(n1,n2,graph):\n",
    "    nei1 = getNeighbors_Source(n1, graph)\n",
    "    nei2 = getNeighbors_Sink(n2, graph)  \n",
    "    cn = set(nei1).intersection(set(nei2))\n",
    "    try:\n",
    "        lhn = len(cn)/(PA(n1,n2,graph))\n",
    "    except:\n",
    "        lhn=0\n",
    "    return lhn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Similarity Features from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    cn.append(CN(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['CN']=cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    aai.append(AAI(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['AAI']=aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    jc.append(JC(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['JC']=jc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    pa.append(PA(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['PA']=pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    ra.append(RA(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['RA']=ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    hp.append(HP(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['HP']=hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhn = []\n",
    "for i in tqdm(range(len(source))):\n",
    "    lhn.append(LHN(source[i],sink[i],graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train['LHN']=lhn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pr = nx.pagerank(graph)\n",
    "with open('PageRank.txt', 'wb') as file:\n",
    "    pickle.dump(pr,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PageRank.txt', 'rb') as file:\n",
    "    pr = pickle.load(file)\n",
    "    \n",
    "dataframe_train['PageRank_Src'] = source.apply(lambda row: pr.get(row))\n",
    "dataframe_train['PageRank_Sink'] = sink.apply(lambda row: pr.get(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Number of Zeros:')\n",
    "dataframe_train.isin([0]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "centrality = nx.eigenvector_centrality(graph)\n",
    "with open('Eigenvector_Centrality.txt', 'wb') as file:\n",
    "    pickle.dump(centrality,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Eigenvector_Centrality.txt', 'rb') as file:\n",
    "    centrality = pickle.load(file)\n",
    "dataframe_train['ECentrality_Sour'] = source.apply(lambda row: centrality.get(row))\n",
    "dataframe_train['ECentrality_Sink'] = sink.apply(lambda row: centrality.get(row))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dc = nx.degree_centrality(graph)\n",
    "with open('Degree_centrality.txt', 'wb') as file:\n",
    "    pickle.dump(dc,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Degree_centrality.txt', 'rb') as file:\n",
    "    dc = pickle.load(file)\n",
    "dataframe_train['Degree_Centrality_Sour'] = source.apply(lambda row: dc.get(row))\n",
    "dataframe_train['Degree_Centrality_Sink'] = sink.apply(lambda row: dc.get(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Number of Zeros:')\n",
    "dataframe_train.isin([0]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Feature Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframe_train.txt','wb') as file:\n",
    "    pickle.dump(dataframe_train,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
